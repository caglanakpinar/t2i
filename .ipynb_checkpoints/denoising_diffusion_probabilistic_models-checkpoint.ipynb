{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c53d76-c400-47e3-9fba-4fc676cff7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Requires TensorFlow >=2.11 for the GroupNormalization layer.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3f68c7-f456-4617-93eb-56769eb720f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 1  # Just for the sake of demonstration\n",
    "total_timesteps = 1000\n",
    "norm_groups = 8  # Number of groups used in GroupNormalization layer\n",
    "learning_rate = 2e-4\n",
    "\n",
    "img_size = 64\n",
    "img_channels = 3\n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "first_conv_channels = 64\n",
    "channel_multiplier = [1, 2, 4, 8]\n",
    "widths = [first_conv_channels * mult for mult in channel_multiplier]\n",
    "has_attention = [False, False, True, True]\n",
    "num_res_blocks = 2  # Number of residual blocks\n",
    "\n",
    "dataset_name = \"oxford_flowers102\"\n",
    "splits = [\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268f6bd3-b755-4219-90ea-eda849a06322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(ds,) = tfds.load(dataset_name, split=splits, with_info=False, shuffle_files=True)\n",
    "\n",
    "\n",
    "def augment(img):\n",
    "    \"\"\"Flips an image left/right randomly.\"\"\"\n",
    "    return tf.image.random_flip_left_right(img)\n",
    "\n",
    "\n",
    "def resize_and_rescale(img, size):\n",
    "    \"\"\"Resize the image to the desired size first and then\n",
    "    rescale the pixel values in the range [-1.0, 1.0].\n",
    "\n",
    "    Args:\n",
    "        img: Image tensor\n",
    "        size: Desired image size for resizing\n",
    "    Returns:\n",
    "        Resized and rescaled image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    height = tf.shape(img)[0]\n",
    "    width = tf.shape(img)[1]\n",
    "    crop_size = tf.minimum(height, width)\n",
    "\n",
    "    img = tf.image.crop_to_bounding_box(\n",
    "        img,\n",
    "        (height - crop_size) // 2,\n",
    "        (width - crop_size) // 2,\n",
    "        crop_size,\n",
    "        crop_size,\n",
    "    )\n",
    "\n",
    "    # Resize\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    img = tf.image.resize(img, size=size, antialias=True)\n",
    "\n",
    "    # Rescale the pixel values\n",
    "    img = img / 127.5 - 1.0\n",
    "    img = tf.clip_by_value(img, clip_min, clip_max)\n",
    "    return img\n",
    "\n",
    "\n",
    "def train_preprocessing(x):\n",
    "    img = x[\"image\"]\n",
    "    img = resize_and_rescale(img, size=(img_size, img_size))\n",
    "    img = augment(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "train_ds = (\n",
    "    ds.map(train_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .shuffle(batch_size * 2)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dca44bd5-f8fd-4d51-8767-c443c0495150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 64, 64, 3), dtype=float32, numpy=\n",
       "array([[[[-0.8306644 , -0.7371212 , -0.95182765],\n",
       "         [-0.7626058 , -0.61431676, -0.93218565],\n",
       "         [-0.729423  , -0.54163826, -0.89981776],\n",
       "         ...,\n",
       "         [-0.80454034, -0.79692495, -0.9529009 ],\n",
       "         [-0.8358447 , -0.77503514, -0.9722911 ],\n",
       "         [-0.89407015, -0.8369471 , -0.98566157]],\n",
       "\n",
       "        [[-0.9097879 , -0.87738204, -0.97831434],\n",
       "         [-0.8989304 , -0.833475  , -0.9730195 ],\n",
       "         [-0.8452291 , -0.72692204, -0.9410543 ],\n",
       "         ...,\n",
       "         [-0.7874836 , -0.7885021 , -0.9680369 ],\n",
       "         [-0.7820765 , -0.707676  , -0.98519665],\n",
       "         [-0.8749994 , -0.82552   , -0.98216295]],\n",
       "\n",
       "        [[-0.9407452 , -0.92313987, -0.9856089 ],\n",
       "         [-0.94402033, -0.92948395, -0.9812078 ],\n",
       "         [-0.9340651 , -0.9103471 , -0.9849005 ],\n",
       "         ...,\n",
       "         [-0.76639307, -0.72621936, -0.946405  ],\n",
       "         [-0.73303014, -0.649737  , -0.9730999 ],\n",
       "         [-0.7895955 , -0.7183142 , -0.96416277]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3641274 ,  0.06890917, -0.15866089],\n",
       "         [ 0.41424   ,  0.16916609, -0.07150424],\n",
       "         [-0.02512103, -0.17301726, -0.56485   ],\n",
       "         ...,\n",
       "         [-0.6619376 , -0.64702046, -0.97172046],\n",
       "         [-0.6065036 , -0.6519943 , -0.95971906],\n",
       "         [-0.6064869 , -0.62635195, -0.92904943]],\n",
       "\n",
       "        [[ 0.3332795 ,  0.05833542, -0.22743505],\n",
       "         [-0.1201576 , -0.30732226, -0.60870206],\n",
       "         [-0.6649824 , -0.63443124, -0.9228317 ],\n",
       "         ...,\n",
       "         [-0.7877714 , -0.78355706, -0.9771082 ],\n",
       "         [-0.62568057, -0.661942  , -0.9557043 ],\n",
       "         [-0.5634707 , -0.63464224, -0.92460245]],\n",
       "\n",
       "        [[-0.06838685, -0.21727061, -0.62903464],\n",
       "         [-0.6116358 , -0.58309144, -0.93302906],\n",
       "         [-0.90730596, -0.8770645 , -0.9949516 ],\n",
       "         ...,\n",
       "         [-0.608065  , -0.4905663 , -0.9413701 ],\n",
       "         [-0.61842144, -0.559306  , -0.9616701 ],\n",
       "         [-0.73210293, -0.7450892 , -0.9784357 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.47565037, -0.50382805, -0.5827857 ],\n",
       "         [-0.36094302, -0.41320187, -0.5587481 ],\n",
       "         [-0.38067484, -0.45489275, -0.5984696 ],\n",
       "         ...,\n",
       "         [-0.3077811 ,  0.08207738, -0.40650702],\n",
       "         [-0.31334835,  0.09268486, -0.4207474 ],\n",
       "         [-0.38363427,  0.04140508, -0.4570989 ]],\n",
       "\n",
       "        [[-0.34744698, -0.40376204, -0.52790576],\n",
       "         [-0.40647155, -0.48082268, -0.62524164],\n",
       "         [-0.58846927, -0.66565865, -0.7715263 ],\n",
       "         ...,\n",
       "         [-0.36869556,  0.00605059, -0.51702666],\n",
       "         [-0.34615368,  0.07848823, -0.39388078],\n",
       "         [-0.3851415 ,  0.05862272, -0.39084035]],\n",
       "\n",
       "        [[-0.5250865 , -0.59821236, -0.69601107],\n",
       "         [-0.5697434 , -0.63174415, -0.707741  ],\n",
       "         [-0.634691  , -0.6988182 , -0.72980535],\n",
       "         ...,\n",
       "         [-0.5094286 , -0.158889  , -0.72446126],\n",
       "         [-0.42343056, -0.00905126, -0.5086494 ],\n",
       "         [-0.4265014 , -0.00461859, -0.44090784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4486035 ,  0.26526415,  0.01506126],\n",
       "         [ 0.41553986,  0.22517848, -0.02974981],\n",
       "         [ 0.3841635 ,  0.19920301, -0.06546003],\n",
       "         ...,\n",
       "         [-0.65939844, -0.6712631 , -0.69654405],\n",
       "         [-0.6701864 , -0.6702853 , -0.67912686],\n",
       "         [-0.6301022 , -0.62990594, -0.6347755 ]],\n",
       "\n",
       "        [[ 0.47314584,  0.27617788,  0.04011905],\n",
       "         [ 0.45450556,  0.25609207,  0.02589583],\n",
       "         [ 0.4267348 ,  0.24076784, -0.01389259],\n",
       "         ...,\n",
       "         [-0.66294956, -0.6716771 , -0.70079577],\n",
       "         [-0.6072418 , -0.6177774 , -0.6251986 ],\n",
       "         [-0.65637547, -0.6650322 , -0.6671433 ]],\n",
       "\n",
       "        [[ 0.43168902,  0.24226856, -0.01919335],\n",
       "         [ 0.45077252,  0.26043355, -0.00123137],\n",
       "         [ 0.41474617,  0.22960949, -0.02246493],\n",
       "         ...,\n",
       "         [-0.5517749 , -0.5698596 , -0.5902604 ],\n",
       "         [-0.559987  , -0.5822357 , -0.592711  ],\n",
       "         [-0.60245574, -0.6182347 , -0.63768446]]],\n",
       "\n",
       "\n",
       "       [[[ 0.25968397,  0.22938013,  0.13543415],\n",
       "         [ 0.30871916,  0.2773652 ,  0.18324745],\n",
       "         [ 0.06436443,  0.03299177, -0.06112587],\n",
       "         ...,\n",
       "         [ 0.14387774,  0.1355617 ,  0.14077985],\n",
       "         [ 0.24154735,  0.24122202,  0.24149895],\n",
       "         [ 0.3151238 ,  0.34860408,  0.33647203]],\n",
       "\n",
       "        [[ 0.1310128 ,  0.10174584,  0.00922537],\n",
       "         [ 0.12800407,  0.0982945 ,  0.0050714 ],\n",
       "         [ 0.21542966,  0.18530047,  0.09067965],\n",
       "         ...,\n",
       "         [ 0.19806302,  0.19032478,  0.19461572],\n",
       "         [ 0.02416325,  0.02517056,  0.02494359],\n",
       "         [ 0.18220961,  0.21599984,  0.20462787]],\n",
       "\n",
       "        [[-0.01766056, -0.03004879, -0.12511617],\n",
       "         [-0.3368016 , -0.35060525, -0.4455002 ],\n",
       "         [ 0.11076677,  0.084342  , -0.01195186],\n",
       "         ...,\n",
       "         [ 0.20619226,  0.19691932,  0.21369171],\n",
       "         [-0.13006026, -0.12265176, -0.11591738],\n",
       "         [ 0.11971056,  0.14777696,  0.14953399]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.08754742,  0.01502359, -0.04254675],\n",
       "         [ 0.15753818,  0.07012081,  0.01966691],\n",
       "         [ 0.00145507, -0.09396058, -0.1509856 ],\n",
       "         ...,\n",
       "         [ 0.36000216,  0.3503778 ,  0.4115672 ],\n",
       "         [ 0.19918573,  0.18694317,  0.2651192 ],\n",
       "         [ 0.23309433,  0.22233403,  0.29653215]],\n",
       "\n",
       "        [[-0.09804362, -0.15455884, -0.21151185],\n",
       "         [-0.11853653, -0.22089529, -0.28302753],\n",
       "         [-0.06597084, -0.17783701, -0.26880598],\n",
       "         ...,\n",
       "         [ 0.29732978,  0.284307  ,  0.3648342 ],\n",
       "         [ 0.20429027,  0.19336033,  0.2592224 ],\n",
       "         [ 0.11514235,  0.10789537,  0.15287042]],\n",
       "\n",
       "        [[-0.03291303, -0.0609296 , -0.12094647],\n",
       "         [-0.02703369, -0.02833897, -0.03389597],\n",
       "         [-0.1535945 , -0.17042595, -0.20952046],\n",
       "         ...,\n",
       "         [ 0.28681076,  0.2715261 ,  0.3652351 ],\n",
       "         [ 0.18386269,  0.17638326,  0.22121334],\n",
       "         [ 0.13941765,  0.13871491,  0.1417929 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.3903942 , -0.01925534, -0.9158785 ],\n",
       "         [-0.36318988,  0.00986278, -0.88688856],\n",
       "         [-0.33316088,  0.04066873, -0.85810196],\n",
       "         ...,\n",
       "         [-0.5220942 , -0.4887421 , -0.6600021 ],\n",
       "         [-0.4934129 , -0.4269933 , -0.62293214],\n",
       "         [-0.56573737, -0.3329082 , -0.71737194]],\n",
       "\n",
       "        [[-0.3346268 , -0.07075065, -0.80825174],\n",
       "         [-0.37093812, -0.11531961, -0.80254537],\n",
       "         [-0.33309758, -0.07592314, -0.7791289 ],\n",
       "         ...,\n",
       "         [-0.50089467, -0.42824847, -0.6591543 ],\n",
       "         [-0.555967  , -0.36314785, -0.7039373 ],\n",
       "         [-0.5617981 , -0.28016227, -0.69668746]],\n",
       "\n",
       "        [[-0.20501864, -0.00215876, -0.6050602 ],\n",
       "         [-0.29117703, -0.09334493, -0.66378915],\n",
       "         [-0.3100732 , -0.07568181, -0.72976947],\n",
       "         ...,\n",
       "         [-0.5167099 , -0.388025  , -0.7005794 ],\n",
       "         [-0.52334344, -0.27639645, -0.64845645],\n",
       "         [-0.46685457, -0.17645508, -0.56810576]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5353923 , -0.62511   , -0.64897764],\n",
       "         [-0.54539657, -0.63370866, -0.67123866],\n",
       "         [-0.55556154, -0.63266313, -0.6767987 ],\n",
       "         ...,\n",
       "         [-0.30332398, -0.2543583 , -0.5511011 ],\n",
       "         [-0.4329908 , -0.42300516, -0.641599  ],\n",
       "         [-0.52383673, -0.56167114, -0.6718528 ]],\n",
       "\n",
       "        [[-0.44295675, -0.5517708 , -0.56143177],\n",
       "         [-0.44894344, -0.55326957, -0.58948696],\n",
       "         [-0.45872146, -0.55410105, -0.59846354],\n",
       "         ...,\n",
       "         [-0.15982199, -0.10726351, -0.36459255],\n",
       "         [-0.30183542, -0.3447554 , -0.4521702 ],\n",
       "         [-0.3711818 , -0.44307816, -0.5190906 ]],\n",
       "\n",
       "        [[-0.37846524, -0.49611896, -0.5091882 ],\n",
       "         [-0.3944922 , -0.4966877 , -0.5414216 ],\n",
       "         [-0.39321643, -0.5001012 , -0.54426694],\n",
       "         ...,\n",
       "         [-0.10371727,  0.0365243 , -0.2941128 ],\n",
       "         [-0.15650326, -0.19243604, -0.3398947 ],\n",
       "         [-0.22216415, -0.24362314, -0.41377646]]],\n",
       "\n",
       "\n",
       "       [[[-0.66386807, -0.5676389 , -0.89608127],\n",
       "         [-0.61125946, -0.5060289 , -0.8741263 ],\n",
       "         [-0.5158824 , -0.405518  , -0.82632786],\n",
       "         ...,\n",
       "         [-0.6345796 , -0.51962817, -0.8605497 ],\n",
       "         [-0.61493015, -0.5115588 , -0.86279356],\n",
       "         [-0.6029401 , -0.49414635, -0.87789065]],\n",
       "\n",
       "        [[-0.6551567 , -0.5598329 , -0.83475375],\n",
       "         [-0.5846432 , -0.48868185, -0.7763737 ],\n",
       "         [-0.46849835, -0.36921525, -0.7292491 ],\n",
       "         ...,\n",
       "         [-0.66648066, -0.553303  , -0.8782492 ],\n",
       "         [-0.6004063 , -0.4949866 , -0.84580356],\n",
       "         [-0.5842952 , -0.4740715 , -0.8540477 ]],\n",
       "\n",
       "        [[-0.5326654 , -0.40888667, -0.7455538 ],\n",
       "         [-0.51477015, -0.39798063, -0.6974021 ],\n",
       "         [-0.4506712 , -0.362624  , -0.6800956 ],\n",
       "         ...,\n",
       "         [-0.6999036 , -0.5797652 , -0.9179701 ],\n",
       "         [-0.6407567 , -0.5187288 , -0.87111336],\n",
       "         [-0.5959156 , -0.47385758, -0.8294982 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5151286 , -0.38456523, -0.69351715],\n",
       "         [-0.55523026, -0.42196518, -0.76245815],\n",
       "         [-0.61521745, -0.47770286, -0.84593093],\n",
       "         ...,\n",
       "         [-0.7035047 , -0.601146  , -0.88760245],\n",
       "         [-0.62373424, -0.5208802 , -0.8132858 ],\n",
       "         [-0.5179279 , -0.41113257, -0.71316916]],\n",
       "\n",
       "        [[-0.513418  , -0.38771635, -0.68058383],\n",
       "         [-0.5136373 , -0.38270187, -0.7065165 ],\n",
       "         [-0.5598516 , -0.4275127 , -0.7631413 ],\n",
       "         ...,\n",
       "         [-0.7432819 , -0.6451645 , -0.88318473],\n",
       "         [-0.6563805 , -0.5680845 , -0.82794505],\n",
       "         [-0.5602    , -0.47031975, -0.7465012 ]],\n",
       "\n",
       "        [[-0.5252795 , -0.40589303, -0.6939528 ],\n",
       "         [-0.53806186, -0.41454202, -0.727002  ],\n",
       "         [-0.66132444, -0.5508198 , -0.81891185],\n",
       "         ...,\n",
       "         [-0.7252428 , -0.6221646 , -0.8679054 ],\n",
       "         [-0.70716107, -0.61887836, -0.85965383],\n",
       "         [-0.70258653, -0.63085175, -0.8640946 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.19738746,  0.11139953, -0.04881978],\n",
       "         [ 0.20776904,  0.12149286, -0.03497696],\n",
       "         [ 0.2210828 ,  0.13283908, -0.01065475],\n",
       "         ...,\n",
       "         [ 0.27214503,  0.0525372 , -0.12001181],\n",
       "         [ 0.19086742, -0.02874053, -0.20128953],\n",
       "         [ 0.11827278, -0.10133517, -0.2767679 ]],\n",
       "\n",
       "        [[ 0.19091403,  0.1067338 , -0.04674482],\n",
       "         [ 0.21162784,  0.12756729, -0.02856207],\n",
       "         [ 0.24278152,  0.15508807, -0.00550878],\n",
       "         ...,\n",
       "         [ 0.3389747 ,  0.11936665, -0.05318224],\n",
       "         [ 0.26707375,  0.0474658 , -0.12508309],\n",
       "         [ 0.19467866, -0.02492911, -0.20007241]],\n",
       "\n",
       "        [[ 0.18169141,  0.11294127, -0.02875972],\n",
       "         [ 0.20930672,  0.14179277, -0.00796437],\n",
       "         [ 0.26853383,  0.16961336,  0.02112341],\n",
       "         ...,\n",
       "         [ 0.39869153,  0.17908382,  0.0065347 ],\n",
       "         [ 0.3423773 ,  0.12276924, -0.04977977],\n",
       "         [ 0.26781023,  0.0482024 , -0.12477678]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4431492 ,  0.31595874,  0.13703239],\n",
       "         [ 0.41249442,  0.2922659 ,  0.11043882],\n",
       "         [ 0.35300696,  0.24080634,  0.04141915],\n",
       "         ...,\n",
       "         [-0.73088974, -0.7430514 , -0.7951397 ],\n",
       "         [-0.7460209 , -0.75663245, -0.7946581 ],\n",
       "         [-0.7550078 , -0.760776  , -0.80404514]],\n",
       "\n",
       "        [[ 0.39381564,  0.25950956,  0.07080662],\n",
       "         [ 0.33296275,  0.21992588,  0.02017307],\n",
       "         [ 0.2303611 ,  0.13121879, -0.08035165],\n",
       "         ...,\n",
       "         [-0.6760001 , -0.7047485 , -0.78064466],\n",
       "         [-0.69948375, -0.7048043 , -0.7664737 ],\n",
       "         [-0.70524937, -0.7062834 , -0.76842964]],\n",
       "\n",
       "        [[ 0.33707166,  0.20990968,  0.00899374],\n",
       "         [ 0.2682054 ,  0.16664982, -0.05740964],\n",
       "         [ 0.15591943,  0.05970514, -0.1619969 ],\n",
       "         ...,\n",
       "         [-0.58410513, -0.6438246 , -0.7345927 ],\n",
       "         [-0.5875802 , -0.64433956, -0.72377276],\n",
       "         [-0.59240294, -0.64868724, -0.72267914]]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_ds.take(1):\n",
    "    print()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c69ffd3d-e42f-40fe-a7e7-3ae28e7a9291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=TensorSpec(shape=(32, 64, 64, 3), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60d94522-e50b-4c10-b348-e579bde01a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"Gaussian diffusion utility.\n",
    "\n",
    "    Args:\n",
    "        beta_start: Start value of the scheduled variance\n",
    "        beta_end: End value of the scheduled variance\n",
    "        timesteps: Number of time steps in the forward process\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        timesteps=1000,\n",
    "        clip_min=-1.0,\n",
    "        clip_max=1.0,\n",
    "    ):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "\n",
    "        # Define the linear variance schedule\n",
    "        self.betas = betas = np.linspace(\n",
    "            beta_start,\n",
    "            beta_end,\n",
    "            timesteps,\n",
    "            dtype=np.float64,  # Using float64 for better precision\n",
    "        )\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "\n",
    "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (\n",
    "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "\n",
    "        # Log calculation clipped because the posterior variance is 0 at the beginning\n",
    "        # of the diffusion chain\n",
    "        self.posterior_log_variance_clipped = tf.constant(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef1 = tf.constant(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef2 = tf.constant(\n",
    "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Extract some coefficients at specified timesteps,\n",
    "        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
    "\n",
    "        Args:\n",
    "            a: Tensor to extract from\n",
    "            t: Timestep for which the coefficients are to be extracted\n",
    "            x_shape: Shape of the current batched samples\n",
    "        \"\"\"\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"Extracts the mean, and the variance at current timestep.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start_shape\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"Diffuse the data.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "            noise: Gaussian noise to be added at the current timestep\n",
    "        Returns:\n",
    "            Diffused samples at timestep `t`\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return (\n",
    "            self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
    "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"Compute the mean and variance of the diffusion\n",
    "        posterior q(x_{t-1} | x_t, x_0).\n",
    "\n",
    "        Args:\n",
    "            x_start: Stating point(sample) for the posterior computation\n",
    "            x_t: Sample at timestep `t`\n",
    "            t: Current timestep\n",
    "        Returns:\n",
    "            Posterior mean and variance at current timestep\n",
    "        \"\"\"\n",
    "\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t_shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t\n",
    "        )\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        \"\"\"Sample from the diffusion model.\n",
    "\n",
    "        Args:\n",
    "            pred_noise: Noise predicted by the diffusion model\n",
    "            x: Samples at a given timestep for which the noise was predicted\n",
    "            t: Current timestep\n",
    "            clip_denoised (bool): Whether to clip the predicted noise\n",
    "                within the specified range or not.\n",
    "        \"\"\"\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            pred_noise, x=x, t=t, clip_denoised=clip_denoised\n",
    "        )\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # No noise when t == 0\n",
    "        nonzero_mask = tf.reshape(\n",
    "            1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1]\n",
    "        )\n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebddb2e6-c259-4907-a386-a336684ab47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.010049999999999998), np.float64(0.005750382688807276))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_start=1e-4\n",
    "beta_end=0.02\n",
    "timesteps=1000\n",
    "clip_min=-1.0\n",
    "clip_max=1.0\n",
    "\n",
    "# Define the linear variance schedule\n",
    "betas = betas = np.linspace(\n",
    "    beta_start,\n",
    "    beta_end,\n",
    "    timesteps,\n",
    "    dtype=np.float64,  # Using float64 for better precision\n",
    ")\n",
    "np.mean(betas), np.std(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64fb9e8e-3691-4f39-8400-294be8bc5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = int(timesteps)\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "betas = tf.constant(betas, dtype=tf.float32)\n",
    "alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f441aaf8-df15-42c0-8357-b455fcacc427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "array([9.99899983e-01, 9.99780059e-01, 9.99640286e-01, 9.99480605e-01,\n",
       "       9.99301016e-01, 9.99101520e-01, 9.98882174e-01, 9.98642981e-01,\n",
       "       9.98383999e-01, 9.98105168e-01, 9.97806549e-01, 9.97488141e-01,\n",
       "       9.97149944e-01, 9.96792018e-01, 9.96414304e-01, 9.96016920e-01,\n",
       "       9.95599866e-01, 9.95163143e-01, 9.94706810e-01, 9.94230807e-01,\n",
       "       9.93735254e-01, 9.93220150e-01, 9.92685556e-01, 9.92131472e-01,\n",
       "       9.91557896e-01, 9.90964949e-01, 9.90352631e-01, 9.89720941e-01,\n",
       "       9.89069939e-01, 9.88399625e-01, 9.87710118e-01, 9.87001419e-01,\n",
       "       9.86273587e-01, 9.85526621e-01, 9.84760582e-01, 9.83975530e-01,\n",
       "       9.83171523e-01, 9.82348561e-01, 9.81506765e-01, 9.80646074e-01,\n",
       "       9.79766607e-01, 9.78868425e-01, 9.77951586e-01, 9.77016151e-01,\n",
       "       9.76062119e-01, 9.75089550e-01, 9.74098563e-01, 9.73089159e-01,\n",
       "       9.72061455e-01, 9.71015394e-01, 9.69951153e-01, 9.68868792e-01,\n",
       "       9.67768312e-01, 9.66649830e-01, 9.65513349e-01, 9.64358985e-01,\n",
       "       9.63186800e-01, 9.61996853e-01, 9.60789204e-01, 9.59563911e-01,\n",
       "       9.58321095e-01, 9.57060814e-01, 9.55783129e-01, 9.54488099e-01,\n",
       "       9.53175783e-01, 9.51846302e-01, 9.50499713e-01, 9.49136078e-01,\n",
       "       9.47755516e-01, 9.46358025e-01, 9.44943786e-01, 9.43512857e-01,\n",
       "       9.42065299e-01, 9.40601230e-01, 9.39120650e-01, 9.37623680e-01,\n",
       "       9.36110437e-01, 9.34580982e-01, 9.33035433e-01, 9.31473792e-01,\n",
       "       9.29896235e-01, 9.28302824e-01, 9.26693678e-01, 9.25068855e-01,\n",
       "       9.23428416e-01, 9.21772540e-01, 9.20101285e-01, 9.18414712e-01,\n",
       "       9.16712940e-01, 9.14996028e-01, 9.13264096e-01, 9.11517262e-01,\n",
       "       9.09755647e-01, 9.07979310e-01, 9.06188309e-01, 9.04382825e-01,\n",
       "       9.02562916e-01, 9.00728703e-01, 8.98880303e-01, 8.97017717e-01,\n",
       "       8.95141125e-01, 8.93250644e-01, 8.91346395e-01, 8.89428437e-01,\n",
       "       8.87496889e-01, 8.85551870e-01, 8.83593440e-01, 8.81621778e-01,\n",
       "       8.79636943e-01, 8.77639055e-01, 8.75628233e-01, 8.73604536e-01,\n",
       "       8.71568143e-01, 8.69519174e-01, 8.67457628e-01, 8.65383685e-01,\n",
       "       8.63297522e-01, 8.61199200e-01, 8.59088838e-01, 8.56966436e-01,\n",
       "       8.54832232e-01, 8.52686346e-01, 8.50528836e-01, 8.48359883e-01,\n",
       "       8.46179545e-01, 8.43987942e-01, 8.41785192e-01, 8.39571476e-01,\n",
       "       8.37346852e-01, 8.35111380e-01, 8.32865238e-01, 8.30608606e-01,\n",
       "       8.28341544e-01, 8.26064169e-01, 8.23776543e-01, 8.21478844e-01,\n",
       "       8.19171250e-01, 8.16853821e-01, 8.14526677e-01, 8.12189877e-01,\n",
       "       8.09843600e-01, 8.07488024e-01, 8.05123210e-01, 8.02749276e-01,\n",
       "       8.00366342e-01, 7.97974527e-01, 7.95573950e-01, 7.93164790e-01,\n",
       "       7.90747106e-01, 7.88321018e-01, 7.85886705e-01, 7.83444226e-01,\n",
       "       7.80993760e-01, 7.78535426e-01, 7.76069283e-01, 7.73595512e-01,\n",
       "       7.71114230e-01, 7.68625498e-01, 7.66129553e-01, 7.63626397e-01,\n",
       "       7.61116207e-01, 7.58599102e-01, 7.56075263e-01, 7.53544748e-01,\n",
       "       7.51007676e-01, 7.48464167e-01, 7.45914400e-01, 7.43358433e-01,\n",
       "       7.40796447e-01, 7.38228500e-01, 7.35654771e-01, 7.33075321e-01,\n",
       "       7.30490327e-01, 7.27899909e-01, 7.25304127e-01, 7.22703218e-01,\n",
       "       7.20097244e-01, 7.17486322e-01, 7.14870572e-01, 7.12250054e-01,\n",
       "       7.09625006e-01, 7.06995487e-01, 7.04361618e-01, 7.01723576e-01,\n",
       "       6.99081361e-01, 6.96435213e-01, 6.93785191e-01, 6.91131473e-01,\n",
       "       6.88474119e-01, 6.85813248e-01, 6.83148980e-01, 6.80481493e-01,\n",
       "       6.77810848e-01, 6.75137222e-01, 6.72460675e-01, 6.69781327e-01,\n",
       "       6.67099297e-01, 6.64414763e-01, 6.61727786e-01, 6.59038484e-01,\n",
       "       6.56346977e-01, 6.53653383e-01, 6.50957823e-01, 6.48260415e-01,\n",
       "       6.45561278e-01, 6.42860532e-01, 6.40158296e-01, 6.37454629e-01,\n",
       "       6.34749711e-01, 6.32043600e-01, 6.29336417e-01, 6.26628339e-01,\n",
       "       6.23919427e-01, 6.21209800e-01, 6.18499517e-01, 6.15788758e-01,\n",
       "       6.13077641e-01, 6.10366225e-01, 6.07654691e-01, 6.04943037e-01,\n",
       "       6.02231443e-01, 5.99520028e-01, 5.96808851e-01, 5.94098091e-01,\n",
       "       5.91387749e-01, 5.88678002e-01, 5.85968971e-01, 5.83260715e-01,\n",
       "       5.80553353e-01, 5.77847004e-01, 5.75141788e-01, 5.72437763e-01,\n",
       "       5.69735050e-01, 5.67033708e-01, 5.64333916e-01, 5.61635733e-01,\n",
       "       5.58939278e-01, 5.56244612e-01, 5.53551853e-01, 5.50861120e-01,\n",
       "       5.48172474e-01, 5.45486033e-01, 5.42801917e-01, 5.40120184e-01,\n",
       "       5.37440956e-01, 5.34764290e-01, 5.32090306e-01, 5.29419124e-01,\n",
       "       5.26750743e-01, 5.24085343e-01, 5.21422982e-01, 5.18763781e-01,\n",
       "       5.16107798e-01, 5.13455153e-01, 5.10805905e-01, 5.08160114e-01,\n",
       "       5.05517960e-01, 5.02879441e-01, 5.00244677e-01, 4.97613758e-01,\n",
       "       4.94986773e-01, 4.92363781e-01, 4.89744902e-01, 4.87130165e-01,\n",
       "       4.84519690e-01, 4.81913567e-01, 4.79311854e-01, 4.76714641e-01,\n",
       "       4.74121988e-01, 4.71534014e-01, 4.68950778e-01, 4.66372341e-01,\n",
       "       4.63798791e-01, 4.61230189e-01, 4.58666623e-01, 4.56108183e-01,\n",
       "       4.53554928e-01, 4.51006949e-01, 4.48464274e-01, 4.45927024e-01,\n",
       "       4.43395227e-01, 4.40868974e-01, 4.38348353e-01, 4.35833395e-01,\n",
       "       4.33324188e-01, 4.30820793e-01, 4.28323299e-01, 4.25831735e-01,\n",
       "       4.23346162e-01, 4.20866668e-01, 4.18393314e-01, 4.15926188e-01,\n",
       "       4.13465321e-01, 4.11010772e-01, 4.08562601e-01, 4.06120867e-01,\n",
       "       4.03685659e-01, 4.01257008e-01, 3.98834944e-01, 3.96419585e-01,\n",
       "       3.94010961e-01, 3.91609102e-01, 3.89214098e-01, 3.86825979e-01,\n",
       "       3.84444803e-01, 3.82070631e-01, 3.79703522e-01, 3.77343506e-01,\n",
       "       3.74990642e-01, 3.72644961e-01, 3.70306551e-01, 3.67975444e-01,\n",
       "       3.65651667e-01, 3.63335282e-01, 3.61026347e-01, 3.58724892e-01,\n",
       "       3.56430948e-01, 3.54144603e-01, 3.51865828e-01, 3.49594712e-01,\n",
       "       3.47331315e-01, 3.45075637e-01, 3.42827737e-01, 3.40587646e-01,\n",
       "       3.38355422e-01, 3.36131096e-01, 3.33914697e-01, 3.31706256e-01,\n",
       "       3.29505801e-01, 3.27313393e-01, 3.25129032e-01, 3.22952777e-01,\n",
       "       3.20784658e-01, 3.18624705e-01, 3.16472948e-01, 3.14329416e-01,\n",
       "       3.12194139e-01, 3.10067177e-01, 3.07948500e-01, 3.05838168e-01,\n",
       "       3.03736210e-01, 3.01642656e-01, 2.99557537e-01, 2.97480851e-01,\n",
       "       2.95412630e-01, 2.93352902e-01, 2.91301697e-01, 2.89259046e-01,\n",
       "       2.87224919e-01, 2.85199404e-01, 2.83182472e-01, 2.81174183e-01,\n",
       "       2.79174536e-01, 2.77183533e-01, 2.75201201e-01, 2.73227572e-01,\n",
       "       2.71262676e-01, 2.69306481e-01, 2.67359018e-01, 2.65420318e-01,\n",
       "       2.63490409e-01, 2.61569291e-01, 2.59656966e-01, 2.57753432e-01,\n",
       "       2.55858719e-01, 2.53972858e-01, 2.52095819e-01, 2.50227630e-01,\n",
       "       2.48368293e-01, 2.46517837e-01, 2.44676262e-01, 2.42843568e-01,\n",
       "       2.41019771e-01, 2.39204854e-01, 2.37398848e-01, 2.35601753e-01,\n",
       "       2.33813569e-01, 2.32034296e-01, 2.30263934e-01, 2.28502497e-01,\n",
       "       2.26749986e-01, 2.25006402e-01, 2.23271742e-01, 2.21545994e-01,\n",
       "       2.19829172e-01, 2.18121275e-01, 2.16422319e-01, 2.14732274e-01,\n",
       "       2.13051140e-01, 2.11378932e-01, 2.09715635e-01, 2.08061263e-01,\n",
       "       2.06415787e-01, 2.04779208e-01, 2.03151524e-01, 2.01532736e-01,\n",
       "       1.99922845e-01, 1.98321819e-01, 1.96729660e-01, 1.95146367e-01,\n",
       "       1.93571940e-01, 1.92006350e-01, 1.90449610e-01, 1.88901678e-01,\n",
       "       1.87362567e-01, 1.85832277e-01, 1.84310779e-01, 1.82798073e-01,\n",
       "       1.81294128e-01, 1.79798946e-01, 1.78312525e-01, 1.76834837e-01,\n",
       "       1.75365880e-01, 1.73905611e-01, 1.72454044e-01, 1.71011165e-01,\n",
       "       1.69576943e-01, 1.68151379e-01, 1.66734442e-01, 1.65326133e-01,\n",
       "       1.63926423e-01, 1.62535295e-01, 1.61152735e-01, 1.59778729e-01,\n",
       "       1.58413246e-01, 1.57056287e-01, 1.55707821e-01, 1.54367834e-01,\n",
       "       1.53036296e-01, 1.51713192e-01, 1.50398508e-01, 1.49092227e-01,\n",
       "       1.47794321e-01, 1.46504760e-01, 1.45223543e-01, 1.43950641e-01,\n",
       "       1.42686024e-01, 1.41429678e-01, 1.40181571e-01, 1.38941690e-01,\n",
       "       1.37710005e-01, 1.36486501e-01, 1.35271147e-01, 1.34063914e-01,\n",
       "       1.32864788e-01, 1.31673738e-01, 1.30490750e-01, 1.29315794e-01,\n",
       "       1.28148824e-01, 1.26989841e-01, 1.25838816e-01, 1.24695711e-01,\n",
       "       1.23560511e-01, 1.22433178e-01, 1.21313691e-01, 1.20202027e-01,\n",
       "       1.19098157e-01, 1.18002050e-01, 1.16913676e-01, 1.15833014e-01,\n",
       "       1.14760034e-01, 1.13694713e-01, 1.12637013e-01, 1.11586906e-01,\n",
       "       1.10544369e-01, 1.09509371e-01, 1.08481884e-01, 1.07461870e-01,\n",
       "       1.06449306e-01, 1.05444163e-01, 1.04446411e-01, 1.03456020e-01,\n",
       "       1.02472961e-01, 1.01497196e-01, 1.00528702e-01, 9.95674506e-02,\n",
       "       9.86134112e-02, 9.76665393e-02, 9.67268199e-02, 9.57942158e-02,\n",
       "       9.48686972e-02, 9.39502269e-02, 9.30387825e-02, 9.21343192e-02,\n",
       "       9.12368149e-02, 9.03462395e-02, 8.94625559e-02, 8.85857344e-02,\n",
       "       8.77157375e-02, 8.68525431e-02, 8.59961137e-02, 8.51464123e-02,\n",
       "       8.43034089e-02, 8.34670737e-02, 8.26373771e-02, 8.18142816e-02,\n",
       "       8.09977502e-02, 8.01877528e-02, 7.93842599e-02, 7.85872415e-02,\n",
       "       7.77966604e-02, 7.70124793e-02, 7.62346685e-02, 7.54631907e-02,\n",
       "       7.46980235e-02, 7.39391223e-02, 7.31864646e-02, 7.24400058e-02,\n",
       "       7.16997162e-02, 7.09655657e-02, 7.02375174e-02, 6.95155412e-02,\n",
       "       6.87996000e-02, 6.80896640e-02, 6.73856959e-02, 6.66876659e-02,\n",
       "       6.59955367e-02, 6.53092712e-02, 6.46288469e-02, 6.39542192e-02,\n",
       "       6.32853657e-02, 6.26222417e-02, 6.19648211e-02, 6.13130666e-02,\n",
       "       6.06669486e-02, 6.00264296e-02, 5.93914799e-02, 5.87620586e-02,\n",
       "       5.81381395e-02, 5.75196855e-02, 5.69066666e-02, 5.62990494e-02,\n",
       "       5.56967929e-02, 5.50998710e-02, 5.45082502e-02, 5.39218970e-02,\n",
       "       5.33407778e-02, 5.27648553e-02, 5.21940999e-02, 5.16284816e-02,\n",
       "       5.10679632e-02, 5.05125150e-02, 4.99620996e-02, 4.94166873e-02,\n",
       "       4.88762446e-02, 4.83407378e-02, 4.78101373e-02, 4.72844057e-02,\n",
       "       4.67635132e-02, 4.62474301e-02, 4.57361229e-02, 4.52295579e-02,\n",
       "       4.47276980e-02, 4.42305170e-02, 4.37379815e-02, 4.32500616e-02,\n",
       "       4.27667238e-02, 4.22879308e-02, 4.18136567e-02, 4.13438715e-02,\n",
       "       4.08785418e-02, 4.04176340e-02, 3.99611145e-02, 3.95089574e-02,\n",
       "       3.90611291e-02, 3.86175998e-02, 3.81783396e-02, 3.77433114e-02,\n",
       "       3.73124890e-02, 3.68858427e-02, 3.64633389e-02, 3.60449478e-02,\n",
       "       3.56306396e-02, 3.52203846e-02, 3.48141529e-02, 3.44119109e-02,\n",
       "       3.40136327e-02, 3.36192846e-02, 3.32288407e-02, 3.28422673e-02,\n",
       "       3.24595384e-02, 3.20806243e-02, 3.17054912e-02, 3.13341133e-02,\n",
       "       3.09664626e-02, 3.06025092e-02, 3.02422252e-02, 2.98855789e-02,\n",
       "       2.95325425e-02, 2.91830879e-02, 2.88371891e-02, 2.84948144e-02,\n",
       "       2.81559359e-02, 2.78205276e-02, 2.74885613e-02, 2.71600094e-02,\n",
       "       2.68348437e-02, 2.65130345e-02, 2.61945575e-02, 2.58793831e-02,\n",
       "       2.55674869e-02, 2.52588410e-02, 2.49534156e-02, 2.46511865e-02,\n",
       "       2.43521277e-02, 2.40562111e-02, 2.37634126e-02, 2.34737024e-02,\n",
       "       2.31870580e-02, 2.29034517e-02, 2.26228591e-02, 2.23452523e-02,\n",
       "       2.20706072e-02, 2.17988975e-02, 2.15300992e-02, 2.12641861e-02,\n",
       "       2.10011341e-02, 2.07409170e-02, 2.04835106e-02, 2.02288926e-02,\n",
       "       1.99770369e-02, 1.97279174e-02, 1.94815118e-02, 1.92377958e-02,\n",
       "       1.89967453e-02, 1.87583379e-02, 1.85225494e-02, 1.82893537e-02,\n",
       "       1.80587303e-02, 1.78306550e-02, 1.76051054e-02, 1.73820592e-02,\n",
       "       1.71614904e-02, 1.69433802e-02, 1.67277046e-02, 1.65144410e-02,\n",
       "       1.63035672e-02, 1.60950609e-02, 1.58889014e-02, 1.56850647e-02,\n",
       "       1.54835312e-02, 1.52842794e-02, 1.50872860e-02, 1.48925316e-02,\n",
       "       1.46999946e-02, 1.45096546e-02, 1.43214902e-02, 1.41354799e-02,\n",
       "       1.39516043e-02, 1.37698427e-02, 1.35901747e-02, 1.34125808e-02,\n",
       "       1.32370396e-02, 1.30635323e-02, 1.28920395e-02, 1.27225406e-02,\n",
       "       1.25550171e-02, 1.23894494e-02, 1.22258179e-02, 1.20641040e-02,\n",
       "       1.19042890e-02, 1.17463544e-02, 1.15902806e-02, 1.14360498e-02,\n",
       "       1.12836435e-02, 1.11330440e-02, 1.09842326e-02, 1.08371908e-02,\n",
       "       1.06919017e-02, 1.05483476e-02, 1.04065109e-02, 1.02663748e-02,\n",
       "       1.01279207e-02, 9.99113172e-03, 9.85599123e-03, 9.72248241e-03,\n",
       "       9.59058851e-03, 9.46029276e-03, 9.33157839e-03, 9.20442957e-03,\n",
       "       9.07883048e-03, 8.95476434e-03, 8.83221440e-03, 8.71116575e-03,\n",
       "       8.59160349e-03, 8.47351085e-03, 8.35687295e-03, 8.24167300e-03,\n",
       "       8.12789705e-03, 8.01553018e-03, 7.90455751e-03, 7.79496366e-03,\n",
       "       7.68673373e-03, 7.57985329e-03, 7.47430837e-03, 7.37008406e-03,\n",
       "       7.26716639e-03, 7.16554094e-03, 7.06519373e-03, 6.96611125e-03,\n",
       "       6.86827954e-03, 6.77168509e-03, 6.67631393e-03, 6.58215303e-03,\n",
       "       6.48918934e-03, 6.39740936e-03, 6.30680006e-03, 6.21734839e-03,\n",
       "       6.12904131e-03, 6.04186673e-03, 5.95581159e-03, 5.87086380e-03,\n",
       "       5.78701030e-03, 5.70423901e-03, 5.62253827e-03, 5.54189598e-03,\n",
       "       5.46229957e-03, 5.38373739e-03, 5.30619826e-03, 5.22967009e-03,\n",
       "       5.15414169e-03, 5.07960143e-03, 5.00603765e-03, 4.93343966e-03,\n",
       "       4.86179627e-03, 4.79109632e-03, 4.72132908e-03, 4.65248339e-03,\n",
       "       4.58454899e-03, 4.51751566e-03, 4.45137220e-03, 4.38610883e-03,\n",
       "       4.32171440e-03, 4.25817957e-03, 4.19549411e-03, 4.13364777e-03,\n",
       "       4.07263078e-03, 4.01243335e-03, 3.95304570e-03, 3.89445829e-03,\n",
       "       3.83666181e-03, 3.77964647e-03, 3.72340297e-03, 3.66792246e-03,\n",
       "       3.61319561e-03, 3.55921336e-03, 3.50596639e-03, 3.45344632e-03,\n",
       "       3.40164430e-03, 3.35055147e-03, 3.30015947e-03, 3.25045944e-03,\n",
       "       3.20144324e-03, 3.15310247e-03, 3.10542877e-03, 3.05841397e-03,\n",
       "       3.01204994e-03, 2.96632876e-03, 2.92124273e-03, 2.87678372e-03,\n",
       "       2.83294404e-03, 2.78971600e-03, 2.74709193e-03, 2.70506437e-03,\n",
       "       2.66362610e-03, 2.62276945e-03, 2.58248718e-03, 2.54277210e-03,\n",
       "       2.50361720e-03, 2.46501551e-03, 2.42695981e-03, 2.38944311e-03,\n",
       "       2.35245889e-03, 2.31600017e-03, 2.28006043e-03, 2.24463316e-03,\n",
       "       2.20971135e-03, 2.17528897e-03, 2.14135949e-03, 2.10791663e-03,\n",
       "       2.07495410e-03, 2.04246561e-03, 2.01044511e-03, 1.97888655e-03,\n",
       "       1.94778398e-03, 1.91713148e-03, 1.88692310e-03, 1.85715314e-03,\n",
       "       1.82781590e-03, 1.79890567e-03, 1.77041686e-03, 1.74234388e-03,\n",
       "       1.71468139e-03, 1.68742391e-03, 1.66056619e-03, 1.63410290e-03,\n",
       "       1.60802866e-03, 1.58233847e-03, 1.55702722e-03, 1.53208990e-03,\n",
       "       1.50752149e-03, 1.48331688e-03, 1.45947142e-03, 1.43598020e-03,\n",
       "       1.41283846e-03, 1.39004155e-03, 1.36758480e-03, 1.34546356e-03,\n",
       "       1.32367341e-03, 1.30220980e-03, 1.28106831e-03, 1.26024440e-03,\n",
       "       1.23973389e-03, 1.21953257e-03, 1.19963614e-03, 1.18004042e-03,\n",
       "       1.16074120e-03, 1.14173454e-03, 1.12301635e-03, 1.10458268e-03,\n",
       "       1.08642958e-03, 1.06855319e-03, 1.05094968e-03, 1.03361520e-03,\n",
       "       1.01654604e-03, 9.99738579e-04, 9.83188977e-04, 9.66893800e-04,\n",
       "       9.50849440e-04, 9.35052405e-04, 9.19499202e-04, 9.04186338e-04,\n",
       "       8.89110495e-04, 8.74268299e-04, 8.59656488e-04, 8.45271745e-04,\n",
       "       8.31110869e-04, 8.17170658e-04, 8.03448027e-04, 7.89939833e-04,\n",
       "       7.76642992e-04, 7.63554475e-04, 7.50671315e-04, 7.37990602e-04,\n",
       "       7.25509424e-04, 7.13224872e-04, 7.01134093e-04, 6.89234294e-04,\n",
       "       6.77522738e-04, 6.65996748e-04, 6.54653530e-04, 6.43490464e-04,\n",
       "       6.32504933e-04, 6.21694373e-04, 6.11056166e-04, 6.00587868e-04,\n",
       "       5.90286916e-04, 5.80150867e-04, 5.70177333e-04, 5.60363871e-04,\n",
       "       5.50708210e-04, 5.41207904e-04, 5.31860685e-04, 5.22664341e-04,\n",
       "       5.13616600e-04, 5.04715252e-04, 4.95958084e-04, 4.87343001e-04,\n",
       "       4.78867878e-04, 4.70530591e-04, 4.62329102e-04, 4.54261346e-04,\n",
       "       4.46325314e-04, 4.38519055e-04, 4.30840591e-04, 4.23288002e-04,\n",
       "       4.15859366e-04, 4.08552820e-04, 4.01366502e-04, 3.94298608e-04,\n",
       "       3.87347332e-04, 3.80510843e-04, 3.73787450e-04, 3.67175409e-04,\n",
       "       3.60673032e-04, 3.54278629e-04, 3.47990514e-04, 3.41807085e-04,\n",
       "       3.35726712e-04, 3.29747825e-04, 3.23868851e-04, 3.18088220e-04,\n",
       "       3.12404445e-04, 3.06816015e-04, 3.01321445e-04, 2.95919250e-04,\n",
       "       2.90608004e-04, 2.85386312e-04, 2.80252745e-04, 2.75205966e-04,\n",
       "       2.70244578e-04, 2.65367242e-04, 2.60572648e-04, 2.55859486e-04,\n",
       "       2.51226476e-04, 2.46672367e-04, 2.42195892e-04, 2.37795830e-04,\n",
       "       2.33470972e-04, 2.29220124e-04, 2.25042109e-04, 2.20935748e-04,\n",
       "       2.16899920e-04, 2.12933490e-04, 2.09035366e-04, 2.05204444e-04,\n",
       "       2.01439630e-04, 1.97739879e-04, 1.94104141e-04, 1.90531384e-04,\n",
       "       1.87020589e-04, 1.83570752e-04, 1.80180898e-04, 1.76850052e-04,\n",
       "       1.73577268e-04, 1.70361600e-04, 1.67202103e-04, 1.64097859e-04,\n",
       "       1.61047981e-04, 1.58051582e-04, 1.55107788e-04, 1.52215725e-04,\n",
       "       1.49374566e-04, 1.46583465e-04, 1.43841593e-04, 1.41148150e-04,\n",
       "       1.38502321e-04, 1.35903334e-04, 1.33350404e-04, 1.30842775e-04,\n",
       "       1.28379703e-04, 1.25960432e-04, 1.23584236e-04, 1.21250414e-04,\n",
       "       1.18958247e-04, 1.16707044e-04, 1.14496113e-04, 1.12324793e-04,\n",
       "       1.10192414e-04, 1.08098320e-04, 1.06041873e-04, 1.04022423e-04,\n",
       "       1.02039361e-04, 1.00092075e-04, 9.81799603e-05, 9.63024140e-05,\n",
       "       9.44588537e-05, 9.26487046e-05, 9.08713992e-05, 8.91263771e-05,\n",
       "       8.74130928e-05, 8.57310006e-05, 8.40795692e-05, 8.24582748e-05,\n",
       "       8.08666009e-05, 7.93040381e-05, 7.77700843e-05, 7.62642521e-05,\n",
       "       7.47860613e-05, 7.33350316e-05, 7.19106974e-05, 7.05125931e-05,\n",
       "       6.91402674e-05, 6.77932694e-05, 6.64711697e-05, 6.51735245e-05,\n",
       "       6.38999118e-05, 6.26499168e-05, 6.14231249e-05, 6.02191358e-05,\n",
       "       5.90375457e-05, 5.78779618e-05, 5.67400020e-05, 5.56232881e-05,\n",
       "       5.45274452e-05, 5.34521023e-05, 5.23969029e-05, 5.13614905e-05,\n",
       "       5.03455158e-05, 4.93486368e-05, 4.83705116e-05, 4.74108092e-05,\n",
       "       4.64692021e-05, 4.55453737e-05, 4.46390040e-05, 4.37497802e-05,\n",
       "       4.28773965e-05, 4.20215583e-05, 4.11819638e-05, 4.03583254e-05],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_cumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "266bd927-7a9e-47d1-8bfa-f8722938ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = (\n",
    "    betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    ")\n",
    "posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "posterior_log_variance_clipped = tf.constant(\n",
    "    np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
    ")\n",
    "posterior_mean_coef1 = tf.constant(\n",
    "    betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "posterior_mean_coef2 = tf.constant(\n",
    "    (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "# Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = tf.constant(\n",
    "    np.sqrt(alphas_cumprod), dtype=tf.float32\n",
    ")\n",
    "sqrt_one_minus_alphas_cumprod = tf.constant(\n",
    "    np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
    ")\n",
    "log_one_minus_alphas_cumprod = tf.constant(\n",
    "    np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
    ")\n",
    "sqrt_recip_alphas_cumprod = tf.constant(\n",
    "    np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
    ")\n",
    "sqrt_recipm1_alphas_cumprod = tf.constant(\n",
    "    np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e169b-d255-4e7d-b4b9-f9fb03acd8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65568249-dd60-4942-9d53-39f868c1846e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ecd5fcd-2363-45eb-a2e2-312ab5cb27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97d5ffa-d790-4963-819d-2acc7473df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method GaussianDiffusion.p_sample of <__main__.GaussianDiffusion object at 0x133639850>>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_util.p_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc9bdc70-2396-4457-bbf6-594b558fccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = i[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e1044b6-5d77-4595-b410-cab83c8ee423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = tf.random.uniform(\n",
    "    minval=0, \n",
    "    maxval=total_timesteps, \n",
    "    shape=(batch_size,), \n",
    "    dtype=tf.int64\n",
    ")\n",
    "noise = tf.random.normal(shape=tf.shape(images), dtype=images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1e9b63f-0394-4af4-8292-8ba79bd366f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "array([0.0001    , 0.00011992, 0.00013984, 0.00015976, 0.00017968,\n",
       "       0.0001996 , 0.00021952, 0.00023944, 0.00025936, 0.00027928,\n",
       "       0.0002992 , 0.00031912, 0.00033904, 0.00035896, 0.00037888,\n",
       "       0.0003988 , 0.00041872, 0.00043864, 0.00045856, 0.00047848,\n",
       "       0.0004984 , 0.00051832, 0.00053824, 0.00055816, 0.00057808,\n",
       "       0.000598  , 0.00061792, 0.00063784, 0.00065776, 0.00067768,\n",
       "       0.0006976 , 0.00071752, 0.00073744, 0.00075736, 0.00077728,\n",
       "       0.0007972 , 0.00081712, 0.00083704, 0.00085696, 0.00087688,\n",
       "       0.0008968 , 0.00091672, 0.00093664, 0.00095656, 0.00097648,\n",
       "       0.0009964 , 0.00101632, 0.00103624, 0.00105616, 0.00107608,\n",
       "       0.001096  , 0.00111592, 0.00113584, 0.00115576, 0.00117568,\n",
       "       0.0011956 , 0.00121552, 0.00123544, 0.00125536, 0.00127528,\n",
       "       0.0012952 , 0.00131512, 0.00133504, 0.00135495, 0.00137487,\n",
       "       0.00139479, 0.00141471, 0.00143463, 0.00145455, 0.00147447,\n",
       "       0.00149439, 0.00151431, 0.00153423, 0.00155415, 0.00157407,\n",
       "       0.00159399, 0.00161391, 0.00163383, 0.00165375, 0.00167367,\n",
       "       0.00169359, 0.00171351, 0.00173343, 0.00175335, 0.00177327,\n",
       "       0.00179319, 0.00181311, 0.00183303, 0.00185295, 0.00187287,\n",
       "       0.00189279, 0.00191271, 0.00193263, 0.00195255, 0.00197247,\n",
       "       0.00199239, 0.00201231, 0.00203223, 0.00205215, 0.00207207,\n",
       "       0.00209199, 0.00211191, 0.00213183, 0.00215175, 0.00217167,\n",
       "       0.00219159, 0.00221151, 0.00223143, 0.00225135, 0.00227127,\n",
       "       0.00229119, 0.00231111, 0.00233103, 0.00235095, 0.00237087,\n",
       "       0.00239079, 0.00241071, 0.00243063, 0.00245055, 0.00247047,\n",
       "       0.00249039, 0.00251031, 0.00253023, 0.00255015, 0.00257007,\n",
       "       0.00258999, 0.00260991, 0.00262983, 0.00264975, 0.00266967,\n",
       "       0.00268959, 0.00270951, 0.00272943, 0.00274935, 0.00276927,\n",
       "       0.00278919, 0.00280911, 0.00282903, 0.00284895, 0.00286887,\n",
       "       0.00288879, 0.00290871, 0.00292863, 0.00294855, 0.00296847,\n",
       "       0.00298839, 0.00300831, 0.00302823, 0.00304815, 0.00306807,\n",
       "       0.00308799, 0.00310791, 0.00312783, 0.00314775, 0.00316767,\n",
       "       0.00318759, 0.00320751, 0.00322743, 0.00324735, 0.00326727,\n",
       "       0.00328719, 0.00330711, 0.00332703, 0.00334695, 0.00336687,\n",
       "       0.00338679, 0.00340671, 0.00342663, 0.00344655, 0.00346647,\n",
       "       0.00348639, 0.00350631, 0.00352623, 0.00354615, 0.00356607,\n",
       "       0.00358599, 0.00360591, 0.00362583, 0.00364575, 0.00366567,\n",
       "       0.00368559, 0.00370551, 0.00372543, 0.00374535, 0.00376527,\n",
       "       0.00378519, 0.00380511, 0.00382502, 0.00384494, 0.00386486,\n",
       "       0.00388478, 0.0039047 , 0.00392462, 0.00394454, 0.00396446,\n",
       "       0.00398438, 0.0040043 , 0.00402422, 0.00404414, 0.00406406,\n",
       "       0.00408398, 0.0041039 , 0.00412382, 0.00414374, 0.00416366,\n",
       "       0.00418358, 0.0042035 , 0.00422342, 0.00424334, 0.00426326,\n",
       "       0.00428318, 0.0043031 , 0.00432302, 0.00434294, 0.00436286,\n",
       "       0.00438278, 0.0044027 , 0.00442262, 0.00444254, 0.00446246,\n",
       "       0.00448238, 0.0045023 , 0.00452222, 0.00454214, 0.00456206,\n",
       "       0.00458198, 0.0046019 , 0.00462182, 0.00464174, 0.00466166,\n",
       "       0.00468158, 0.0047015 , 0.00472142, 0.00474134, 0.00476126,\n",
       "       0.00478118, 0.0048011 , 0.00482102, 0.00484094, 0.00486086,\n",
       "       0.00488078, 0.0049007 , 0.00492062, 0.00494054, 0.00496046,\n",
       "       0.00498038, 0.0050003 , 0.00502022, 0.00504014, 0.00506006,\n",
       "       0.00507998, 0.0050999 , 0.00511982, 0.00513974, 0.00515966,\n",
       "       0.00517958, 0.0051995 , 0.00521942, 0.00523934, 0.00525926,\n",
       "       0.00527918, 0.0052991 , 0.00531902, 0.00533894, 0.00535886,\n",
       "       0.00537878, 0.0053987 , 0.00541862, 0.00543854, 0.00545846,\n",
       "       0.00547838, 0.0054983 , 0.00551822, 0.00553814, 0.00555806,\n",
       "       0.00557798, 0.0055979 , 0.00561782, 0.00563774, 0.00565766,\n",
       "       0.00567758, 0.0056975 , 0.00571742, 0.00573734, 0.00575726,\n",
       "       0.00577718, 0.0057971 , 0.00581702, 0.00583694, 0.00585686,\n",
       "       0.00587678, 0.0058967 , 0.00591662, 0.00593654, 0.00595646,\n",
       "       0.00597638, 0.0059963 , 0.00601622, 0.00603614, 0.00605606,\n",
       "       0.00607598, 0.0060959 , 0.00611582, 0.00613574, 0.00615566,\n",
       "       0.00617558, 0.0061955 , 0.00621542, 0.00623534, 0.00625526,\n",
       "       0.00627518, 0.0062951 , 0.00631501, 0.00633493, 0.00635485,\n",
       "       0.00637477, 0.00639469, 0.00641461, 0.00643453, 0.00645445,\n",
       "       0.00647437, 0.00649429, 0.00651421, 0.00653413, 0.00655405,\n",
       "       0.00657397, 0.00659389, 0.00661381, 0.00663373, 0.00665365,\n",
       "       0.00667357, 0.00669349, 0.00671341, 0.00673333, 0.00675325,\n",
       "       0.00677317, 0.00679309, 0.00681301, 0.00683293, 0.00685285,\n",
       "       0.00687277, 0.00689269, 0.00691261, 0.00693253, 0.00695245,\n",
       "       0.00697237, 0.00699229, 0.00701221, 0.00703213, 0.00705205,\n",
       "       0.00707197, 0.00709189, 0.00711181, 0.00713173, 0.00715165,\n",
       "       0.00717157, 0.00719149, 0.00721141, 0.00723133, 0.00725125,\n",
       "       0.00727117, 0.00729109, 0.00731101, 0.00733093, 0.00735085,\n",
       "       0.00737077, 0.00739069, 0.00741061, 0.00743053, 0.00745045,\n",
       "       0.00747037, 0.00749029, 0.00751021, 0.00753013, 0.00755005,\n",
       "       0.00756997, 0.00758989, 0.00760981, 0.00762973, 0.00764965,\n",
       "       0.00766957, 0.00768949, 0.00770941, 0.00772933, 0.00774925,\n",
       "       0.00776917, 0.00778909, 0.00780901, 0.00782893, 0.00784885,\n",
       "       0.00786877, 0.00788869, 0.00790861, 0.00792853, 0.00794845,\n",
       "       0.00796837, 0.00798829, 0.00800821, 0.00802813, 0.00804805,\n",
       "       0.00806797, 0.00808789, 0.00810781, 0.00812773, 0.00814765,\n",
       "       0.00816757, 0.00818749, 0.00820741, 0.00822733, 0.00824725,\n",
       "       0.00826717, 0.00828709, 0.00830701, 0.00832693, 0.00834685,\n",
       "       0.00836677, 0.00838669, 0.00840661, 0.00842653, 0.00844645,\n",
       "       0.00846637, 0.00848629, 0.00850621, 0.00852613, 0.00854605,\n",
       "       0.00856597, 0.00858589, 0.00860581, 0.00862573, 0.00864565,\n",
       "       0.00866557, 0.00868549, 0.00870541, 0.00872533, 0.00874525,\n",
       "       0.00876516, 0.00878508, 0.008805  , 0.00882492, 0.00884484,\n",
       "       0.00886477, 0.00888469, 0.0089046 , 0.00892452, 0.00894444,\n",
       "       0.00896436, 0.00898428, 0.0090042 , 0.00902412, 0.00904404,\n",
       "       0.00906396, 0.00908388, 0.0091038 , 0.00912372, 0.00914364,\n",
       "       0.00916356, 0.00918348, 0.0092034 , 0.00922332, 0.00924324,\n",
       "       0.00926316, 0.00928308, 0.009303  , 0.00932292, 0.00934284,\n",
       "       0.00936276, 0.00938268, 0.0094026 , 0.00942252, 0.00944244,\n",
       "       0.00946236, 0.00948228, 0.0095022 , 0.00952212, 0.00954204,\n",
       "       0.00956196, 0.00958188, 0.0096018 , 0.00962172, 0.00964164,\n",
       "       0.00966156, 0.00968148, 0.0097014 , 0.00972132, 0.00974124,\n",
       "       0.00976116, 0.00978108, 0.009801  , 0.00982092, 0.00984084,\n",
       "       0.00986076, 0.00988068, 0.0099006 , 0.00992052, 0.00994044,\n",
       "       0.00996036, 0.00998028, 0.0100002 , 0.01002012, 0.01004004,\n",
       "       0.01005996, 0.01007988, 0.0100998 , 0.01011972, 0.01013964,\n",
       "       0.01015956, 0.01017948, 0.0101994 , 0.01021932, 0.01023924,\n",
       "       0.01025916, 0.01027908, 0.010299  , 0.01031892, 0.01033884,\n",
       "       0.01035876, 0.01037868, 0.0103986 , 0.01041852, 0.01043844,\n",
       "       0.01045836, 0.01047828, 0.0104982 , 0.01051812, 0.01053804,\n",
       "       0.01055796, 0.01057788, 0.0105978 , 0.01061772, 0.01063764,\n",
       "       0.01065756, 0.01067748, 0.0106974 , 0.01071732, 0.01073724,\n",
       "       0.01075716, 0.01077708, 0.010797  , 0.01081692, 0.01083684,\n",
       "       0.01085676, 0.01087668, 0.0108966 , 0.01091652, 0.01093644,\n",
       "       0.01095636, 0.01097628, 0.0109962 , 0.01101612, 0.01103604,\n",
       "       0.01105596, 0.01107588, 0.0110958 , 0.01111572, 0.01113564,\n",
       "       0.01115556, 0.01117548, 0.0111954 , 0.01121532, 0.01123524,\n",
       "       0.01125516, 0.01127508, 0.011295  , 0.01131491, 0.01133483,\n",
       "       0.01135475, 0.01137467, 0.01139459, 0.01141451, 0.01143443,\n",
       "       0.01145435, 0.01147427, 0.01149419, 0.01151411, 0.01153403,\n",
       "       0.01155395, 0.01157387, 0.01159379, 0.01161371, 0.01163363,\n",
       "       0.01165355, 0.01167347, 0.01169339, 0.01171331, 0.01173323,\n",
       "       0.01175315, 0.01177307, 0.01179299, 0.01181291, 0.01183283,\n",
       "       0.01185275, 0.01187267, 0.01189259, 0.01191251, 0.01193243,\n",
       "       0.01195235, 0.01197227, 0.01199219, 0.01201211, 0.01203203,\n",
       "       0.01205195, 0.01207187, 0.01209179, 0.01211171, 0.01213163,\n",
       "       0.01215155, 0.01217147, 0.01219139, 0.01221131, 0.01223123,\n",
       "       0.01225115, 0.01227107, 0.01229099, 0.01231091, 0.01233083,\n",
       "       0.01235075, 0.01237067, 0.01239059, 0.01241051, 0.01243043,\n",
       "       0.01245035, 0.01247027, 0.01249019, 0.01251011, 0.01253003,\n",
       "       0.01254995, 0.01256987, 0.01258979, 0.01260971, 0.01262963,\n",
       "       0.01264955, 0.01266947, 0.01268939, 0.01270931, 0.01272923,\n",
       "       0.01274915, 0.01276907, 0.01278899, 0.01280891, 0.01282883,\n",
       "       0.01284875, 0.01286867, 0.01288859, 0.01290851, 0.01292843,\n",
       "       0.01294835, 0.01296827, 0.01298819, 0.01300811, 0.01302803,\n",
       "       0.01304795, 0.01306787, 0.01308779, 0.01310771, 0.01312763,\n",
       "       0.01314755, 0.01316747, 0.01318739, 0.01320731, 0.01322723,\n",
       "       0.01324715, 0.01326707, 0.01328699, 0.01330691, 0.01332683,\n",
       "       0.01334675, 0.01336667, 0.01338659, 0.01340651, 0.01342643,\n",
       "       0.01344635, 0.01346627, 0.01348619, 0.01350611, 0.01352603,\n",
       "       0.01354595, 0.01356587, 0.01358579, 0.01360571, 0.01362563,\n",
       "       0.01364555, 0.01366547, 0.01368539, 0.01370531, 0.01372522,\n",
       "       0.01374514, 0.01376506, 0.01378499, 0.01380491, 0.01382483,\n",
       "       0.01384474, 0.01386466, 0.01388458, 0.0139045 , 0.01392442,\n",
       "       0.01394434, 0.01396426, 0.01398418, 0.0140041 , 0.01402402,\n",
       "       0.01404394, 0.01406386, 0.01408378, 0.0141037 , 0.01412362,\n",
       "       0.01414354, 0.01416346, 0.01418338, 0.0142033 , 0.01422322,\n",
       "       0.01424314, 0.01426306, 0.01428298, 0.0143029 , 0.01432282,\n",
       "       0.01434274, 0.01436266, 0.01438258, 0.0144025 , 0.01442242,\n",
       "       0.01444234, 0.01446226, 0.01448218, 0.0145021 , 0.01452202,\n",
       "       0.01454194, 0.01456186, 0.01458178, 0.0146017 , 0.01462162,\n",
       "       0.01464154, 0.01466146, 0.01468138, 0.0147013 , 0.01472122,\n",
       "       0.01474114, 0.01476106, 0.01478098, 0.0148009 , 0.01482082,\n",
       "       0.01484074, 0.01486066, 0.01488058, 0.0149005 , 0.01492042,\n",
       "       0.01494034, 0.01496026, 0.01498018, 0.0150001 , 0.01502002,\n",
       "       0.01503994, 0.01505986, 0.01507978, 0.0150997 , 0.01511962,\n",
       "       0.01513954, 0.01515946, 0.01517938, 0.0151993 , 0.01521922,\n",
       "       0.01523914, 0.01525906, 0.01527898, 0.0152989 , 0.01531882,\n",
       "       0.01533874, 0.01535866, 0.01537858, 0.0153985 , 0.01541842,\n",
       "       0.01543834, 0.01545826, 0.01547818, 0.0154981 , 0.01551802,\n",
       "       0.01553794, 0.01555786, 0.01557778, 0.0155977 , 0.01561762,\n",
       "       0.01563754, 0.01565746, 0.01567738, 0.0156973 , 0.01571722,\n",
       "       0.01573714, 0.01575706, 0.01577698, 0.0157969 , 0.01581682,\n",
       "       0.01583674, 0.01585666, 0.01587658, 0.0158965 , 0.01591642,\n",
       "       0.01593634, 0.01595626, 0.01597618, 0.0159961 , 0.01601602,\n",
       "       0.01603594, 0.01605586, 0.01607578, 0.0160957 , 0.01611562,\n",
       "       0.01613554, 0.01615546, 0.01617538, 0.0161953 , 0.01621521,\n",
       "       0.01623514, 0.01625505, 0.01627498, 0.01629489, 0.01631482,\n",
       "       0.01633473, 0.01635465, 0.01637457, 0.01639449, 0.01641442,\n",
       "       0.01643433, 0.01645425, 0.01647417, 0.01649409, 0.01651401,\n",
       "       0.01653393, 0.01655385, 0.01657377, 0.01659369, 0.01661361,\n",
       "       0.01663353, 0.01665345, 0.01667337, 0.01669329, 0.01671321,\n",
       "       0.01673313, 0.01675305, 0.01677297, 0.01679289, 0.01681281,\n",
       "       0.01683273, 0.01685265, 0.01687257, 0.01689249, 0.01691241,\n",
       "       0.01693233, 0.01695225, 0.01697217, 0.01699209, 0.01701201,\n",
       "       0.01703193, 0.01705185, 0.01707177, 0.01709169, 0.01711161,\n",
       "       0.01713153, 0.01715145, 0.01717137, 0.01719129, 0.01721121,\n",
       "       0.01723113, 0.01725105, 0.01727097, 0.01729089, 0.01731081,\n",
       "       0.01733073, 0.01735065, 0.01737057, 0.01739049, 0.01741041,\n",
       "       0.01743033, 0.01745025, 0.01747017, 0.01749009, 0.01751001,\n",
       "       0.01752993, 0.01754985, 0.01756977, 0.01758969, 0.01760961,\n",
       "       0.01762953, 0.01764945, 0.01766937, 0.01768929, 0.01770921,\n",
       "       0.01772913, 0.01774905, 0.01776897, 0.01778889, 0.01780881,\n",
       "       0.01782873, 0.01784865, 0.01786857, 0.01788849, 0.01790841,\n",
       "       0.01792833, 0.01794825, 0.01796817, 0.01798809, 0.01800801,\n",
       "       0.01802793, 0.01804785, 0.01806777, 0.01808769, 0.01810761,\n",
       "       0.01812753, 0.01814745, 0.01816737, 0.01818729, 0.01820721,\n",
       "       0.01822713, 0.01824705, 0.01826697, 0.01828689, 0.01830681,\n",
       "       0.01832673, 0.01834665, 0.01836657, 0.01838649, 0.01840641,\n",
       "       0.01842633, 0.01844625, 0.01846617, 0.01848609, 0.01850601,\n",
       "       0.01852593, 0.01854585, 0.01856577, 0.01858569, 0.0186056 ,\n",
       "       0.01862553, 0.01864544, 0.01866537, 0.01868529, 0.01870521,\n",
       "       0.01872513, 0.01874504, 0.01876497, 0.01878488, 0.01880481,\n",
       "       0.01882472, 0.01884465, 0.01886456, 0.01888448, 0.0189044 ,\n",
       "       0.01892432, 0.01894424, 0.01896416, 0.01898408, 0.019004  ,\n",
       "       0.01902392, 0.01904384, 0.01906376, 0.01908368, 0.0191036 ,\n",
       "       0.01912352, 0.01914344, 0.01916336, 0.01918328, 0.0192032 ,\n",
       "       0.01922312, 0.01924304, 0.01926296, 0.01928288, 0.0193028 ,\n",
       "       0.01932272, 0.01934264, 0.01936256, 0.01938248, 0.0194024 ,\n",
       "       0.01942232, 0.01944224, 0.01946216, 0.01948208, 0.019502  ,\n",
       "       0.01952192, 0.01954184, 0.01956176, 0.01958168, 0.0196016 ,\n",
       "       0.01962152, 0.01964144, 0.01966136, 0.01968128, 0.0197012 ,\n",
       "       0.01972112, 0.01974104, 0.01976096, 0.01978088, 0.0198008 ,\n",
       "       0.01982072, 0.01984064, 0.01986056, 0.01988048, 0.0199004 ,\n",
       "       0.01992032, 0.01994024, 0.01996016, 0.01998008, 0.02      ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_util.betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9507a9fa-1050-4f91-b64c-4b17a8c636a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_start_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(\u001b[43mx_start\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_alphas_cumprod, t, tf\u001b[38;5;241m.\u001b[39mshape(x_start)) \u001b[38;5;241m*\u001b[39m x_start\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_one_minus_alphas_cumprod, t, x_start_shape)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m*\u001b[39m noise\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_start' is not defined"
     ]
    }
   ],
   "source": [
    "x_start_shape = tf.shape(x_start)\n",
    "return (\n",
    "    self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "    + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "    * noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "099d633a-9d7f-476f-ba63-75d8c780e08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 32 values, but the requested shape has 64 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Diffuse the images with noise\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m images_t \u001b[38;5;241m=\u001b[39m \u001b[43mgdf_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 123\u001b[0m, in \u001b[0;36mGaussianDiffusion.q_sample\u001b[0;34m(self, x_start, t, noise)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Diffuse the data.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Diffused samples at timestep `t`\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m x_start_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(x_start)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt_alphas_cumprod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x_start\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_one_minus_alphas_cumprod, t, x_start_shape)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;241m*\u001b[39m noise\n\u001b[1;32m    126\u001b[0m )\n",
      "Cell \u001b[0;32mIn[20], line 94\u001b[0m, in \u001b[0;36mGaussianDiffusion._extract\u001b[0;34m(self, a, t, x_shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(a, t)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/t2i-1YvYBAmX-py3.11/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/t2i-1YvYBAmX-py3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/t2i-1YvYBAmX-py3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 32 values, but the requested shape has 64 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "# 4. Diffuse the images with noise\n",
    "images_t = gdf_util.q_sample(images, t, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a22799-b85e-4d2b-9964-90728939b465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
